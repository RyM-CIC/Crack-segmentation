{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, UpSampling2D, AveragePooling2D\n",
    "from keras.models import Model\n",
    "from glob import glob\n",
    "import re\n",
    "import os.path\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras.backend as K\n",
    "\n",
    "image_shape = (320,480)\n",
    "data_dir = './data_mio'\n",
    "namefile = 'grieta'\n",
    "batch_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(data_folder, image_shape, batch_size):\n",
    "    \"\"\"  Create batches of training and validation data \"\"\"\n",
    "    image_paths = glob(os.path.join(data_folder, 'images', '*.png'))\n",
    "    label_paths = {\n",
    "        re.sub(r'_road_', '_', os.path.basename(path)): path\n",
    "        for path in glob(os.path.join(data_folder, 'labels', '*_road_*.png'))}\n",
    "    \n",
    "    background_color = np.array([255, 0, 255])  ## Solo el magenta\n",
    "\n",
    "    random.shuffle(image_paths)\n",
    "    while 1: \n",
    "        for batch_i in range(0, len(image_paths), batch_size):\n",
    "            images = []\n",
    "            gt_images = []\n",
    "            for image_file in image_paths[batch_i:batch_i+batch_size]:\n",
    "                gt_image_file = label_paths[os.path.basename(image_file)]\n",
    "                image = scipy.misc.imread(image_file)\n",
    "                gt_image = scipy.misc.imread(gt_image_file)\n",
    "                #image = scipy.misc.imresize(scipy.misc.imread(image_file), image_shape)\n",
    "                #gt_image = scipy.misc.imresize(scipy.misc.imread(gt_image_file), image_shape)\n",
    "                gt_bg = np.all(gt_image == background_color, axis=2)  #Binarizar la segmentación del target\n",
    "                gt_bg = gt_bg.reshape(*gt_bg.shape, 1)   # Añadirle una dimensión al tensor\n",
    "                gt_image = np.concatenate((gt_bg, np.invert(gt_bg)), axis=2)  #crear dos capas reflejo\n",
    "                images.append(image)\n",
    "                gt_images.append(gt_image)\n",
    "                \n",
    "            X = np.array(images)\n",
    "            Y = np.array(gt_images)\n",
    "            yield (X, Y)\n",
    "        \n",
    "train_generator = generator(os.path.join(data_dir, 'training'), image_shape, batch_size)\n",
    "validation_generator = generator(os.path.join(data_dir, 'validation'), image_shape, batch_size)\n",
    "test_generator = generator(os.path.join(data_dir, 'test'), image_shape, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1 (y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    tp = K.sum(y_true_f * y_pred_f)        # suma de una AND   son los True Points\n",
    "    fp = K.sum(K.clip(K.clip(y_pred_f+y_true_f,0,1)-y_true_f,0,1))\n",
    "    fn = K.sum(K.clip(K.clip(y_pred_f+y_true_f,0,1)-y_pred_f,0,1))\n",
    "    Pr = tp/(tp+fp)\n",
    "    Re = tp/(tp+fn)\n",
    "    f1t = 2*(Pr*Re)/(Pr+Re)\n",
    "    return f1t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net-A model\n",
    "\n",
    "def unet(img_rows, img_cols, img_channels):  # 23 trainable layers, use same padding, en lugar de unpadding layers\n",
    "    x = Input(shape=(img_rows, img_cols, img_channels))\n",
    "    \n",
    "    # Encoder \n",
    "    conv1 = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    conv2 = Conv2D(64, (3, 3), padding='same', activation='relu')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    #pool1 = AveragePooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(128, (3, 3), padding='same', activation='relu')(pool1)\n",
    "    conv4 = Conv2D(128, (3, 3), padding='same', activation='relu')(conv3)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    #pool2 = AveragePooling2D(pool_size=(2, 2))(conv4)\n",
    "    \n",
    "    conv5 = Conv2D(256, (3, 3), padding='same', activation='relu')(pool2)\n",
    "    conv6 = Conv2D(256, (3, 3), padding='same', activation='relu')(conv5)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv6)\n",
    "    #pool3 = AveragePooling2D(pool_size=(2, 2))(conv6)\n",
    "    \n",
    "    conv7 = Conv2D(512, (3, 3), padding='same', activation='relu')(pool3)\n",
    "    conv8 = Conv2D(512, (3, 3), padding='same', activation='relu')(conv7)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv8)\n",
    "    #pool4 = AveragePooling2D(pool_size=(2, 2))(conv8)\n",
    "    \n",
    "    conv9 = Conv2D(1024, (3, 3), padding='same', activation='relu')(pool4)\n",
    "    conv10 = Conv2D(1024, (3, 3), padding='same', activation='relu')(conv9)\n",
    "    \n",
    "    # Decoder\n",
    "    convT1 = Conv2D(512, (2, 2), padding='same', activation='relu')(UpSampling2D(size=(2, 2))(conv10))\n",
    "    merge1 = concatenate([convT1, conv8], axis=3)\n",
    "    conv11 = Conv2D(512, (3, 3), padding='same', activation='relu')(merge1)\n",
    "    conv12 = Conv2D(512, (3, 3), padding='same', activation='relu')(conv11)\n",
    "    \n",
    "    convT2 = Conv2D(256, (2, 2), padding='same', activation='relu')(UpSampling2D(size=(2, 2))(conv12))\n",
    "    merge2 = concatenate([convT2, conv6], axis=3)\n",
    "    conv13 = Conv2D(256, (3, 3), padding='same', activation='relu')(merge2)\n",
    "    conv14 = Conv2D(256, (3, 3), padding='same', activation='relu')(conv13)\n",
    "    \n",
    "    convT3 = Conv2D(128, (2, 2), padding='same', activation='relu')(UpSampling2D(size=(2, 2))(conv14))\n",
    "    merge3 = concatenate([convT3, conv4], axis=3)\n",
    "    conv15 = Conv2D(128, (3, 3), padding='same', activation='relu')(merge3)\n",
    "    conv16 = Conv2D(128, (3, 3), padding='same', activation='relu')(conv15)\n",
    "    \n",
    "    convT4 = Conv2D(64, (2, 2), padding='same', activation='relu')(UpSampling2D(size=(2, 2))(conv16))\n",
    "    merge4 = concatenate([convT4, conv2], axis=3)\n",
    "    conv17 = Conv2D(64, (3, 3), padding='same', activation='relu')(merge4)\n",
    "    conv18 = Conv2D(64, (3, 3), padding='same', activation='relu')(conv17)\n",
    "\n",
    "    y = Conv2D(2, (1, 1), activation='softmax')(conv18)\n",
    "\n",
    "    return Model(inputs=x, outputs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net-B Model\n",
    "\n",
    "def unetB(img_rows, img_cols, img_channels):\n",
    "    x = Input(shape=(img_rows, img_cols, img_channels))\n",
    "    \n",
    "    conv1 = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    conv2 = Conv2D(64, (3, 3), padding='same', activation='relu')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(128, (3, 3), padding='same', activation='relu')(pool1)\n",
    "    conv4 = Conv2D(128, (3, 3), padding='same', activation='relu')(conv3)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    \n",
    "    conv5 = Conv2D(256, (3, 3), padding='same', activation='relu')(pool2)\n",
    "    conv6 = Conv2D(256, (3, 3), padding='same', activation='relu')(conv5)\n",
    "    \n",
    "    \n",
    "    convT3 = Conv2D(128, (2, 2), padding='same', activation='relu')(UpSampling2D(size=(2, 2))(conv6))\n",
    "    merge3 = concatenate([convT3, conv4], axis=3)\n",
    "    conv15 = Conv2D(128, (3, 3), padding='same', activation='relu')(merge3)\n",
    "    conv16 = Conv2D(128, (3, 3), padding='same', activation='relu')(conv15)\n",
    "    \n",
    "    convT4 = Conv2D(64, (2, 2), padding='same', activation='relu')(UpSampling2D(size=(2, 2))(conv16))\n",
    "    merge4 = concatenate([convT4, conv2], axis=3)\n",
    "    conv17 = Conv2D(64, (3, 3), padding='same', activation='relu')(merge4)\n",
    "    conv18 = Conv2D(64, (3, 3), padding='same', activation='relu')(conv17)\n",
    "    \n",
    "    \n",
    "    y = Conv2D(2, (1, 1), activation='softmax')(conv18)\n",
    "\n",
    "    return Model(inputs=x, outputs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net-C model\n",
    "\n",
    "def unetC(img_rows, img_cols, img_channels):  #lr = 0.0009\n",
    "    x = Input(shape=(img_rows, img_cols, img_channels))\n",
    "    \n",
    "    # Encoder \n",
    "    conv1 = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    conv2 = Conv2D(64, (1, 1), padding='same', activation='relu')(conv1)\n",
    "    pool = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    \n",
    "    conv3 = Conv2D(128, (3, 3), padding='same', activation='relu')(pool)\n",
    "    conv4 = Conv2D(128, (1, 1), padding='same', activation='relu')(conv3)\n",
    "    \n",
    "    # Decoder   \n",
    "    convT = Conv2D(64, (2, 2), padding='same', activation='relu')(UpSampling2D(size=(2, 2))(conv4))\n",
    "    merge = concatenate([convT, conv2], axis=3)\n",
    "    conv5 = Conv2D(64, (3, 3), padding='same', activation='relu')(merge)\n",
    "    conv6 = Conv2D(64, (1, 1), padding='same', activation='relu')(conv5)\n",
    "    \n",
    "    # Segmentation\n",
    "    y = Conv2D(2, (1, 1), activation='softmax')(conv6)\n",
    "\n",
    "    return Model(inputs=x, outputs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unetB(image_shape[0],image_shape[1],3)\n",
    "adam = optimizers.Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0) # lr = 0.0009\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=[f1])\n",
    "checkpointer = ModelCheckpoint(filepath='bestmodel_' + namefile + '.h5', monitor='val_loss', verbose=0, save_best_only=True,\n",
    "                              mode='min', period=1)\n",
    "\n",
    "h = model.fit_generator(generator = train_generator, steps_per_epoch=200//batch_size, epochs=5, verbose=1, callbacks=[checkpointer], \n",
    "                        validation_data=validation_generator, validation_steps=18//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('bestmodel_grieta_unetb1' + '.h5')\n",
    "\n",
    "\n",
    "score_train = model.evaluate_generator(train_generator, steps=18//batch_size)\n",
    "print('training', score_train)\n",
    "score_val = model.evaluate_generator(validation_generator, steps=18//batch_size)\n",
    "print('validation', score_val)\n",
    "score_test = model.evaluate_generator(test_generator, steps=38//batch_size)\n",
    "print('test', score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15,15) \n",
    "\n",
    "data_folder = './resultados/aiglern/' \n",
    "th_segment = 0.5\n",
    "k = 10\n",
    "filelist = glob(os.path.join(data_folder, '*.png'))\n",
    "\n",
    "i = 1\n",
    "\n",
    "inicio = time.time()\n",
    "\n",
    "for image_file in filelist[0:k]:\n",
    "    img_original = scipy.misc.imread(image_file)\n",
    "    img = scipy.misc.imresize(img_original, image_shape) \n",
    "    y = model.predict(np.expand_dims(img, axis=0), batch_size=1)   \n",
    "    mask = np.stack([y[0,:,:,0] > th_segment,np.zeros(image_shape),np.zeros(image_shape)], axis=2)\n",
    "    masked = np.ma.masked_array(mask, img).astype('float32')\n",
    "    z = str(i).zfill(3)\n",
    "    i += 1\n",
    "    \n",
    "fin = time.time()\n",
    "print ((fin-inicio)/10)\n",
    "\n",
    "\n",
    "data_folder = './resultados/uneta/aiglern/'\n",
    "k = 10\n",
    "filelist = glob(os.path.join(data_folder, '*.png'))\n",
    "i = 1\n",
    "f1t = 0\n",
    "prt = 0\n",
    "ret = 0\n",
    "for image_file in filelist[0:k]:\n",
    "    img = scipy.misc.imread(image_file)\n",
    "    img = np.asarray(img)\n",
    "    a = scipy.misc.imread('./resultados/labels_aiglern/'+str(i).zfill(3)+'b.png')  \n",
    "    b = np.empty([len(a),len(a[0])])\n",
    "    for m in range (len(a)):\n",
    "        for n in range (len (a[0])):\n",
    "            if a[m][n][0] == 0:\n",
    "                b[m][n] = 0\n",
    "            else:\n",
    "                b[m][n] = 1\n",
    "\n",
    "    c = np.empty([len(img),len(img[0])])\n",
    "    for m in range (len(img)):\n",
    "        for n in range (len (img[0])):\n",
    "            if img[m][n][0] == 0:\n",
    "                c[m][n] = 0\n",
    "            else:\n",
    "                c[m][n] = 1\n",
    "\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    for r in range(len(c)):\n",
    "        for o in range(len(c[0])):\n",
    "            if c[r][o] == 1 and b[r-5:r+5,o-5:o+5].sum() >= 1:\n",
    "                tp += 1\n",
    "            elif c[r][o] == 1 and b[r][o] == 0:\n",
    "                fp += 1\n",
    "            elif c[r-5:r+5,o-5:o+5].sum() == 0 and b[r][o] == 1:\n",
    "                fn += 1\n",
    "    pr = tp/(tp+fp)\n",
    "    re = tp/(tp+fn)\n",
    "    f1 = 2*(pr*re)/(pr+re)\n",
    "    print (i,' Pr: ',pr, 'Re: ', re, 'F1: ', f1)\n",
    "    \n",
    "    f1t = (f1t+f1)\n",
    "    prt = prt+pr\n",
    "    ret = ret+re\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "print (' PrT: ', prt/10, ' ReT: ', ret/10, 'F1T: ', f1t/10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
